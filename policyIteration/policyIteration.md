# On running the policy iteration algorithm.

The area in the top left corners still has the highest values when following our policies for most reward.

At low rewards, the agent is suboptimal. Consistently sticking around the top left corner area.

When we increase the goal reward, and motivating the agent with random actions, then it ends up taking actions that lead us towards the end goal.
